# 抖音与B站华为相关内容用户情感分析对比

## 项目技术汇报

---

## 一、项目概述

本项目旨在对比分析**B站**和**抖音**两大平台上华为相关内容的用户情感差异，通过数据采集、清洗、NLP处理、情感分析和可视化等技术手段，构建用户情感画像并计算跨平台认可度。

### 数据规模
| 平台 | 数据类型 | 数据量 |
|------|----------|--------|
| B站 | 视频、评论、创作者 | 2,851 条 |
| 抖音 | 内容、评论 | 3,076 条 |
| **合计** | - | **5,927 条** |

---

## 二、技术架构

```
┌─────────────────────────────────────────────────────────────┐
│                        数据采集层                            │
│                   Spider (爬虫模块)                          │
└─────────────────────┬───────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────────────┐
│                        数据清洗层                            │
│              DataCleaning (Pandas + 正则表达式)              │
└─────────────────────┬───────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────────────┐
│                        数据分析层                            │
│  ┌─────────────────────┐    ┌─────────────────────────────┐ │
│  │ 评论情感画像分析     │    │ 跨平台认可度分析            │ │
│  │ - 文本预处理(jieba) │    │ - 互动得分计算(Scipy)       │ │
│  │ - LDA主题建模(Gensim)│   │ - 情感得分计算              │ │
│  │ - 情感分析(RoBERTa) │    │ - 认可度综合计算            │ │
│  └─────────────────────┘    └─────────────────────────────┘ │
└─────────────────────┬───────────────────────────────────────┘
                      ↓
┌─────────────────────────────────────────────────────────────┐
│                        可视化层                              │
│            Matplotlib + Seaborn + WordCloud                  │
└─────────────────────────────────────────────────────────────┘
```

---

## 三、核心技术实现

### 3.1 数据清洗模块

**技术栈**: Pandas, NumPy, 正则表达式

#### 3.1.1 主要功能
1. **去重处理**: 基于唯一ID（video_id, comment_id, aweme_id）删除重复记录
2. **缺失值填充**: 互动数据填0，文本字段填空字符串
3. **数据类型转换**: 将中文数值单位转换为数字

#### 3.1.2 中文数值转换算法
```python
def convert_interaction_value(value):
    """将 '1.2万' 转换为 12000"""
    patterns = [
        (r'(\d+\.?\d*)\s*万', 10000),   # 万
        (r'(\d+\.?\d*)\s*千', 1000),    # 千
        (r'(\d+\.?\d*)\s*亿', 100000000), # 亿
    ]
    for pattern, multiplier in patterns:
        match = re.search(pattern, value_str)
        if match:
            return float(match.group(1)) * multiplier
```

#### 3.1.3 多编码读取
支持 `utf-8-sig`, `utf-8`, `gbk`, `gb18030` 等多种编码，解决中文CSV乱码问题。

---

### 3.2 文本预处理模块

**技术栈**: jieba, 正则表达式, Pandas

#### 3.2.1 文本清洗流程
```python
def clean_text(text):
    text = re.sub(r'\[.*?\]', '', text)              # 去除表情 [赞]
    text = re.sub(r'@\S+', '', text)                 # 去除@用户
    text = re.sub(r'http\S+', '', text)              # 去除URL
    text = re.sub(r'[^\u4e00-\u9fa5a-zA-Z0-9]', ' ', text)  # 保留中英文数字
    text = re.sub(r'\s+', ' ', text)                 # 合并空白
    return text.strip()
```

#### 3.2.2 分词策略
- **工具**: jieba分词
- **自定义词典**: 添加华为相关专有名词（华为、麒麟、鸿蒙、Mate60、遥遥领先等）
- **停用词过滤**: 过滤"的"、"了"、"是"等无意义高频词
- **过滤规则**: 单字词、纯数字、短评论（<3词）

---

### 3.3 LDA主题建模

**技术栈**: Gensim

#### 3.3.1 算法原理
LDA（Latent Dirichlet Allocation）是一种无监督的主题模型，假设：
- 每篇文档是多个主题的混合
- 每个主题是多个词的概率分布

#### 3.3.2 实现流程
```python
# 1. 构建词典和语料库
dictionary = corpora.Dictionary(tokenized_texts)
dictionary.filter_extremes(no_below=5, no_above=0.5)  # 过滤极端词频
corpus = [dictionary.doc2bow(text) for text in tokenized_texts]

# 2. 训练LDA模型
model = LdaModel(
    corpus=corpus,
    id2word=dictionary,
    num_topics=4,        # 主题数
    passes=15,           # 迭代次数
    alpha='auto',        # 自动学习文档-主题分布先验
    eta='auto'           # 自动学习主题-词分布先验
)

# 3. 为每条评论分配主题
topic_dist = model.get_document_topics(bow)
best_topic = max(topic_dist, key=lambda x: x[1])
```

---

### 3.4 情感分析模块

**技术栈**: PyTorch, Transformers (Hugging Face)

#### 3.4.1 预训练模型
使用 **RoBERTa** 中文情感分析模型:
- 模型: `uer/roberta-base-finetuned-jd-binary-chinese`
- 基于京东商品评论数据微调
- 输出: 正面概率 (0~1)

#### 3.4.2 实现流程
```python
class SentimentAnalyzer:
    def __init__(self):
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_name)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
    
    def analyze_single(self, text):
        inputs = self.tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
        with torch.no_grad():
            outputs = self.model(**inputs)
        probs = torch.softmax(outputs.logits, dim=1)
        return probs[0][1].item()  # 正面概率
```

#### 3.4.3 情感标签划分
| 得分区间 | 标签 |
|----------|------|
| ≥ 0.7 | 正面 |
| 0.4 ~ 0.7 | 中性 |
| < 0.4 | 负面 |

---

### 3.5 互动得分与认可度计算

**技术栈**: Pandas, NumPy, SciPy

#### 3.5.1 互动率(Engagement Rate)计算

**B站**:
```
ER = (点赞 + 收藏 + 评论 + 分享 + 投币) / 播放量 × 100%
```

**抖音**(无播放量数据):
```
ER = 总互动量 / 平台最大互动量 × 100%
```

#### 3.5.2 百分位归一化
使用 `scipy.stats.percentileofscore` 将ER归一化到0~1:
```python
def percentile_normalize(series):
    return series.apply(lambda x: percentileofscore(series, x) / 100)
```

#### 3.5.3 认可度计算公式
```
单条认可度 = α × 互动得分(归一化) + β × 情感得分
平台认可度 = Σ(认可度_i × 互动量_i) / Σ(互动量_i)
```
其中 α=0.6, β=0.4

---

### 3.6 可视化模块

**技术栈**: Matplotlib, Seaborn, WordCloud

#### 生成图表
| 图表 | 说明 |
|------|------|
| 情感分布对比图 | 直方图 + 柱状图对比两平台情感分布 |
| 主题分布对比图 | 柱状图展示各主题占比 |
| 主题-情感热力图 | Heatmap展示主题与情感的交叉分布 |
| 平台整体对比图 | 综合对比平均情感、正面率、数据量 |
| 词云图 | 按平台/主题生成关键词词云 |

---

## 四、项目结构

```
Data Science/
├── Spider/                     # 数据采集模块
├── DataCleaning/               # 数据清洗模块
│   ├── data_cleaning.py        # 核心清洗代码
│   ├── check_data_quality.py   # 数据质量检查
│   └── cleaned_data/           # 清洗后数据
│       ├── bili/               # B站数据
│       └── dy/                 # 抖音数据
├── Analysis/                   # 数据分析模块
│   ├── CommentSentimentProfile/  # 评论情感画像
│   │   ├── main.py             # 主程序
│   │   └── src/
│   │       ├── data_loader.py      # 数据加载
│   │       ├── text_processor.py   # 文本预处理
│   │       ├── lda_model.py        # LDA主题建模
│   │       ├── sentiment_analyzer.py # 情感分析
│   │       ├── visualizer.py       # 可视化
│   │       └── wordcloud_generator.py # 词云生成
│   └── CrossPlatformApproval/    # 跨平台认可度
│       └── src/
│           ├── data_loader.py      # 数据加载
│           ├── interaction_score.py # 互动得分
│           ├── approval_calculator.py # 认可度计算
│           └── visualizer.py       # 可视化
└── data/                       # 原始数据
```

---

## 五、技术栈总结

| 类别 | 技术/库 | 用途 |
|------|---------|------|
| 数据处理 | Pandas, NumPy | 数据框操作、数值计算 |
| 文本处理 | jieba, re | 中文分词、正则匹配 |
| 主题建模 | Gensim | LDA主题模型 |
| 深度学习 | PyTorch, Transformers | 情感分析(RoBERTa) |
| 统计分析 | SciPy | 百分位归一化 |
| 可视化 | Matplotlib, Seaborn, WordCloud | 图表生成 |

---

## 六、分析流程总结

```
原始数据 → 数据清洗 → 文本预处理 → LDA主题建模
                                        ↓
                              情感分析(RoBERTa)
                                        ↓
                              认可度计算
                                        ↓
                              可视化输出
```

---

## 七、创新点

1. **多平台对比**: 同时分析B站和抖音两大平台，揭示不同用户群体的情感差异
2. **预训练模型应用**: 使用RoBERTa中文情感模型，相比传统词典方法准确率更高
3. **综合认可度指标**: 结合互动数据和情感数据，构建更全面的认可度评估体系
4. **自动化流程**: 从数据清洗到可视化全流程自动化，可复用于其他话题分析

---

*汇报完毕，谢谢！*
