"""
å°çº¢ä¹¦ï¼ˆXiaoHongShuï¼‰çˆ¬è™«
ç”¨äºçˆ¬å–åä¸ºç›¸å…³ç¬”è®°æ•°æ®
æ³¨æ„ï¼šå°çº¢ä¹¦æœ‰è¾ƒå¼ºçš„åçˆ¬æœºåˆ¶ï¼Œå¯èƒ½éœ€è¦ä½¿ç”¨seleniumæˆ–API
"""
import requests
import json
import time
import re
from datetime import datetime
from typing import List, Dict
import random
from urllib.parse import quote


class XiaohongshuSpider:
    def __init__(self, debug: bool = False, cookie_file: str = 'xhs_cookies.pkl'):
        """
        åˆå§‹åŒ–çˆ¬è™«
        :param debug: æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼
        :param cookie_file: Cookieä¿å­˜æ–‡ä»¶è·¯å¾„
        """
        self.debug = debug
        self.cookie_file = cookie_file
        self.headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Referer': 'https://www.xiaohongshu.com/',
            'Accept': 'application/json, text/plain, */*',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Origin': 'https://www.xiaohongshu.com'
        }
        self.session = requests.Session()
        self.session.headers.update(self.headers)
        self.base_url = "https://edith.xiaohongshu.com"
    
    def search_notes(self, keyword: str = "åä¸º", page: int = 1, page_size: int = 20) -> List[Dict]:
        """
        æœç´¢ç¬”è®°
        æ³¨æ„ï¼šå°çº¢ä¹¦APIéœ€è¦ç™»å½•tokenï¼Œè¿™é‡Œæä¾›åŸºç¡€æ¡†æ¶
        """
        # å°çº¢ä¹¦æœç´¢APIï¼ˆéœ€è¦ç™»å½•ï¼‰
        url = f"{self.base_url}/api/sns/web/v1/search/notes"
        params = {
            'keyword': keyword,
            'page': page,
            'page_size': page_size,
            'sort': 'general',  # ç»¼åˆæ’åº
            'note_type': 0  # 0-å…¨éƒ¨ï¼Œ1-è§†é¢‘ï¼Œ2-å›¾æ–‡
        }
        
        # æ³¨æ„ï¼šå®é™…ä½¿ç”¨æ—¶éœ€è¦æ·»åŠ cookieæˆ–token
        # cookies = {
        #     'web_session': 'your_session_token',
        #     # å…¶ä»–å¿…è¦çš„cookies
        # }
        # self.session.cookies.update(cookies)
        
        try:
            response = self.session.get(url, params=params, timeout=10)
            response.raise_for_status()
            data = response.json()
            
            if data.get('success', False):
                notes = []
                for item in data.get('data', {}).get('items', []):
                    note_info = self._parse_note_info(item)
                    if note_info:
                        notes.append(note_info)
                return notes
            else:
                print(f"æœç´¢å¤±è´¥: {data.get('msg', 'æœªçŸ¥é”™è¯¯')}")
                return []
        except Exception as e:
            print(f"æœç´¢ç¬”è®°æ—¶å‡ºé”™: {e}")
            print("æç¤ºï¼šå°çº¢ä¹¦éœ€è¦ç™»å½•tokenï¼Œè¯·ä½¿ç”¨seleniumæ–¹å¼æˆ–é…ç½®cookie")
            return []
    
    def _parse_note_info(self, item: Dict) -> Dict:
        """
        è§£æç¬”è®°ä¿¡æ¯
        """
        try:
            note_card = item.get('note_card', {})
            if not note_card:
                return None
            
            note_id = note_card.get('note_id', '')
            user_info = note_card.get('user', {})
            
            # è§£ææ—¶é—´æˆ³
            time_ms = note_card.get('time', 0)
            publish_date = datetime.fromtimestamp(time_ms / 1000).strftime('%Y-%m-%d %H:%M:%S') if time_ms else ''
            
            # è§£ææ ‡ç­¾
            tag_list = note_card.get('tag_list', [])
            tags = ','.join([tag.get('name', '') for tag in tag_list if isinstance(tag, dict)])
            
            # è·å–äº’åŠ¨æ•°æ®
            interact_info = note_card.get('interact_info', {})
            
            return {
                'Post_ID': note_id,
                'Platform': 'XiaoHongShu',
                'Publish_Date': publish_date,
                'Post_URL': f"https://www.xiaohongshu.com/explore/{note_id}",
                'Author_ID': str(user_info.get('user_id', '')),
                'Author_Name': user_info.get('nickname', ''),
                'Title': note_card.get('title', ''),
                'Content': note_card.get('desc', ''),
                'Tags': tags,
                'Like_Count': interact_info.get('liked_count', 0),
                'Comment_Count': interact_info.get('comment_count', 0),
                'Collect_Count': interact_info.get('collected_count', 0),
                'Share_Count': interact_info.get('share_count', 0),
                'View_Count': interact_info.get('viewed_count', 0)
            }
        except Exception as e:
            print(f"è§£æç¬”è®°ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return None
    
    def crawl_with_selenium(self, keyword: str = "åä¸º", max_pages: int = 10) -> List[Dict]:
        """
        ä½¿ç”¨Seleniumæ–¹å¼çˆ¬å–ï¼ˆæ¨èï¼‰
        éœ€è¦å®‰è£…seleniumå’Œwebdriver
        """
        try:
            from selenium import webdriver
            from selenium.webdriver.common.by import By
            from selenium.webdriver.support.ui import WebDriverWait
            from selenium.webdriver.support import expected_conditions as EC
            from selenium.webdriver.chrome.options import Options
            from selenium.common.exceptions import TimeoutException
        except ImportError:
            print("è¯·å®‰è£…selenium: pip install selenium")
            return []
        
        all_notes = []
        
        # é…ç½®Chromeé€‰é¡¹
        chrome_options = Options()
        # æš‚æ—¶å…³é—­æ— å¤´æ¨¡å¼ï¼Œä¾¿äºè°ƒè¯•
        # chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--disable-gpu')
        
        driver = None
        try:
            # å°è¯•ä½¿ç”¨webdriver-managerè‡ªåŠ¨ç®¡ç†ChromeDriver
            try:
                from selenium.webdriver.chrome.service import Service
                from webdriver_manager.chrome import ChromeDriverManager
                service = Service(ChromeDriverManager().install())
                driver = webdriver.Chrome(service=service, options=chrome_options)
            except ImportError:
                # å¦‚æœæ²¡æœ‰webdriver-managerï¼Œä½¿ç”¨ç³»ç»ŸPATHä¸­çš„ChromeDriver
                driver = webdriver.Chrome(options=chrome_options)
            
            driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
            
            # å…ˆè®¿é—®ä¸»é¡µï¼Œå°è¯•åŠ è½½ä¿å­˜çš„Cookie
            print("æ­£åœ¨åŠ è½½Cookie...")
            driver.get("https://www.xiaohongshu.com")
            time.sleep(2)
            
            # å°è¯•åŠ è½½ä¿å­˜çš„Cookie
            cookies_loaded = self._load_cookies(driver)
            if cookies_loaded:
                print("âœ“ CookieåŠ è½½æˆåŠŸï¼Œåˆ·æ–°é¡µé¢...")
                driver.refresh()
                time.sleep(2)
            else:
                print("æœªæ‰¾åˆ°ä¿å­˜çš„Cookieï¼Œéœ€è¦æ‰‹åŠ¨ç™»å½•")
            
            # è®¿é—®æœç´¢é¡µé¢
            search_url = f"https://www.xiaohongshu.com/search_result?keyword={quote(keyword)}"
            print(f"æ­£åœ¨è®¿é—®: {search_url}")
            driver.get(search_url)
            time.sleep(3)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
            need_login = False
            try:
                # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•æç¤ºæˆ–ç™»å½•æŒ‰é’®
                login_indicators = [
                    ".login-container",
                    "[class*='login']",
                    ".login-btn",
                    "button:contains('ç™»å½•')",
                    "a[href*='login']"
                ]
                for indicator in login_indicators:
                    try:
                        elements = driver.find_elements(By.CSS_SELECTOR, indicator)
                        if elements:
                            need_login = True
                            break
                    except:
                        continue
                
                # æ£€æŸ¥æ˜¯å¦èƒ½çœ‹åˆ°æœç´¢ç»“æœï¼ˆå¦‚æœæ²¡æœ‰ç»“æœå¯èƒ½æ˜¯éœ€è¦ç™»å½•ï¼‰
                try:
                    note_elements = driver.find_elements(By.CSS_SELECTOR, ".note-item, [class*='note']")
                    if not note_elements:
                        # æ£€æŸ¥æ˜¯å¦æœ‰"è¯·ç™»å½•"æç¤º
                        page_text = driver.page_source
                        if 'ç™»å½•' in page_text or 'login' in page_text.lower():
                            need_login = True
                except:
                    pass
                
                if need_login:
                    print("\n" + "="*60)
                    print("âš ï¸  æ£€æµ‹åˆ°éœ€è¦ç™»å½•ï¼")
                    print("="*60)
                    print("è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨ç™»å½•è´¦å·")
                    print("ç™»å½•æ­¥éª¤ï¼š")
                    print("  1. åœ¨æ‰“å¼€çš„æµè§ˆå™¨çª—å£ä¸­ç‚¹å‡»ç™»å½•æŒ‰é’®")
                    print("  2. è¾“å…¥ä½ çš„å°çº¢ä¹¦è´¦å·å’Œå¯†ç ")
                    print("  3. å®Œæˆç™»å½•åï¼Œçˆ¬è™«å°†è‡ªåŠ¨ç»§ç»­...")
                    print("="*60)
                    print("ç­‰å¾…60ç§’ï¼Œè¯·å®Œæˆç™»å½•...")
                    
                    # ç­‰å¾…ç”¨æˆ·ç™»å½•
                    for i in range(60, 0, -10):
                        print(f"  è¿˜å‰© {i} ç§’...", end='\r')
                        time.sleep(10)
                    print("\n")
                    
                    # ç™»å½•ååˆ·æ–°é¡µé¢
                    driver.refresh()
                    time.sleep(3)
                    
                    # ä¿å­˜Cookie
                    self._save_cookies(driver)
                    print("âœ“ Cookieå·²ä¿å­˜ï¼Œä¸‹æ¬¡è¿è¡Œå¯è‡ªåŠ¨ç™»å½•")
            except Exception as e:
                if self.debug:
                    print(f"[DEBUG] æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {e}")
            
            # å°è¯•å…³é—­ç™»å½•å¼¹çª—ï¼ˆå¦‚æœæœ‰ï¼‰
            try:
                close_selectors = [
                    ".close-btn", 
                    ".login-close", 
                    "[class*='close']",
                    "[aria-label*='å…³é—­']",
                    "[aria-label*='Close']"
                ]
                for selector in close_selectors:
                    try:
                        close_btn = WebDriverWait(driver, 2).until(
                            EC.element_to_be_clickable((By.CSS_SELECTOR, selector))
                        )
                        close_btn.click()
                        time.sleep(1)
                        break
                    except:
                        continue
            except:
                pass
            
            # ç­‰å¾…é¡µé¢åŠ è½½ - ä½¿ç”¨æ›´é€šç”¨çš„é€‰æ‹©å™¨
            try:
                WebDriverWait(driver, 15).until(
                    EC.presence_of_element_located((By.CSS_SELECTOR, ".feeds-page, .note-item, [class*='note'], [class*='feed']"))
                )
            except TimeoutException:
                print("é¡µé¢åŠ è½½è¶…æ—¶ï¼Œå°è¯•ç»§ç»­...")
                time.sleep(3)
            
            # æ»šåŠ¨åŠ è½½æ›´å¤š
            for page in range(max_pages):
                print(f"æ­£åœ¨çˆ¬å–å°çº¢ä¹¦ç¬¬ {page + 1} é¡µ...")
                
                # æ»šåŠ¨é¡µé¢
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # è·å–ç¬”è®°å…ƒç´  - ä½¿ç”¨å¤šç§é€‰æ‹©å™¨å°è¯•
                note_elements = []
                selectors = [
                    ".note-item",
                    "[class*='note']",
                    "[class*='feed']",
                    ".feeds-page > div",
                    "a[href*='/explore/']"
                ]
                for selector in selectors:
                    note_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                    if note_elements:
                        print(f"  ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(note_elements)} ä¸ªå…ƒç´ ")
                        break
                
                page_notes = []
                for i, element in enumerate(note_elements):
                    try:
                        if self.debug:
                            print(f"\n[DEBUG] æ­£åœ¨è§£æç¬¬ {i+1}/{len(note_elements)} ä¸ªç¬”è®°å…ƒç´ ...")
                        note_info = self._parse_selenium_element(element, driver)
                        if note_info and note_info.get('Post_ID'):
                            # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨
                            existing_ids = [n['Post_ID'] for n in all_notes]
                            if note_info['Post_ID'] not in existing_ids:
                                all_notes.append(note_info)
                                page_notes.append(note_info)
                                if self.debug:
                                    print(f"[DEBUG] âœ“ æˆåŠŸè§£æç¬”è®° {note_info['Post_ID']}: ç‚¹èµ={note_info.get('Like_Count')}, è¯„è®º={note_info.get('Comment_Count')}, æ”¶è—={note_info.get('Collect_Count')}")
                    except Exception as e:
                        if self.debug:
                            print(f"[DEBUG] âœ— è§£æç¬”è®°å…ƒç´ å¤±è´¥: {e}")
                        continue
                
                print(f"ç¬¬ {page + 1} é¡µæˆåŠŸè§£æ {len(page_notes)} æ¡æ•°æ®ï¼ˆç´¯è®¡ {len(all_notes)} æ¡ï¼‰")
                
                print(f"ç¬¬ {page + 1} é¡µè·å–åˆ° {len(note_elements)} æ¡æ•°æ®")
                time.sleep(random.uniform(2, 3))
            
        except Exception as e:
            print(f"Seleniumçˆ¬å–æ—¶å‡ºé”™: {e}")
        finally:
            if driver:
                driver.quit()
        
        print(f"å°çº¢ä¹¦çˆ¬å–å®Œæˆï¼Œå…±è·å– {len(all_notes)} æ¡æ•°æ®")
        
        # çˆ¬å–å®Œæˆåå†æ¬¡ä¿å­˜Cookieï¼ˆç¡®ä¿æ˜¯æœ€æ–°çš„ï¼‰
        if driver:
            try:
                self._save_cookies(driver)
                if self.debug:
                    print("[DEBUG] Cookieå·²æ›´æ–°ä¿å­˜")
            except:
                pass
        
        return all_notes
    
    def _parse_selenium_element(self, element, driver=None) -> Dict:
        """
        è§£æSeleniumè·å–çš„å…ƒç´ 
        """
        try:
            if self.debug:
                print(f"\n[DEBUG] å¼€å§‹è§£æå°çº¢ä¹¦å…ƒç´ ...")
            
            # è·å–é“¾æ¥å’Œç¬”è®°ID
            href = ''
            note_id = ''
            
            # å°è¯•å¤šç§æ–¹å¼è·å–é“¾æ¥
            try:
                link_elem = element.find_element(By.TAG_NAME, "a")
                href = link_elem.get_attribute('href')
            except:
                href = element.get_attribute('href')
            
            # ä»é“¾æ¥ä¸­æå–ç¬”è®°ID
            if href:
                match = re.search(r'/explore/([a-f0-9]+)', href)
                if match:
                    note_id = match.group(1)
                else:
                    # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é“¾æ¥çš„ä¸€éƒ¨åˆ†ä½œä¸ºID
                    note_id = href.split('/')[-1] or str(hash(href))[:16]
            
            # å¦‚æœæ²¡æœ‰IDï¼Œç”Ÿæˆä¸€ä¸ªåŸºäºå…ƒç´ ä½ç½®çš„ID
            if not note_id:
                note_id = f"xhs_{hash(str(element.location))}"
            
            # è·å–æ ‡é¢˜ - ä½¿ç”¨æ›´é€šç”¨çš„æ–¹æ³•
            title = ''
            # å…ˆå°è¯•ä»é“¾æ¥å…ƒç´ è·å–
            try:
                link_elem = element.find_element(By.TAG_NAME, "a")
                if link_elem:
                    title = link_elem.text.strip()
            except:
                pass
            
            # å¦‚æœè¿˜æ²¡æœ‰ï¼Œå°è¯•å¤šç§é€‰æ‹©å™¨
            if not title:
                title_selectors = [
                    ".title", 
                    "[class*='title']", 
                    "[class*='Title']",
                    "h3", 
                    "h2",
                    "a[href*='/explore/']",
                    ".note-item-title",
                    "[data-v-]"
                ]
                for selector in title_selectors:
                    try:
                        title_elem = element.find_element(By.CSS_SELECTOR, selector)
                        title = title_elem.text.strip()
                        if title and len(title) > 3:  # ç¡®ä¿æ ‡é¢˜æœ‰æ„ä¹‰
                            break
                    except:
                        continue
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰ï¼Œå°è¯•ä»æ•´ä¸ªå…ƒç´ çš„æ–‡æœ¬ä¸­æå–ï¼ˆå–ç¬¬ä¸€è¡Œï¼Œè·³è¿‡æ•°å­—å’Œæ—¶é—´ï¼‰
            if not title:
                try:
                    all_text = element.text.strip()
                    lines = all_text.split('\n')
                    for line in lines:
                        line = line.strip()
                        # è·³è¿‡çº¯æ•°å­—ã€æ—¶é—´ã€ç‚¹èµæ•°ç­‰ï¼Œä½†ä¿ç•™å¯èƒ½çš„æ ‡é¢˜
                        if (line and len(line) > 3 and 
                            not line.isdigit() and 
                            'èµ' not in line and 
                            'æ”¶è—' not in line and
                            'è¯„è®º' not in line and
                            not re.match(r'^\d+\.?\d*[ä¸‡]?$', line) and
                            not re.match(r'^\d+åˆ†é’Ÿå‰$', line) and
                            not re.match(r'^\d+å°æ—¶å‰$', line)):
                            title = line
                            break
                except:
                    pass
            
            # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ ‡é¢˜ï¼Œè‡³å°‘ä½¿ç”¨ä¸€ä¸ªé»˜è®¤å€¼ï¼Œé¿å…è¢«è¿‡æ»¤
            if not title:
                title = "å°çº¢ä¹¦ç¬”è®°"  # ä¸´æ—¶æ ‡é¢˜ï¼Œåç»­å¯ä»¥é€šè¿‡URLè·å–
            
            # è·å–ä½œè€…ä¿¡æ¯ - ä½¿ç”¨æ›´é€šç”¨çš„æ–¹æ³•
            author_name = ''
            author_selectors = [
                ".author", 
                "[class*='author']", 
                "[class*='user']", 
                "[class*='User']",
                ".nickname",
                "[class*='nickname']",
                "[class*='Nickname']",
                ".username",
                "[data-v-]"
            ]
            for selector in author_selectors:
                try:
                    author_elem = element.find_element(By.CSS_SELECTOR, selector)
                    author_name = author_elem.text.strip()
                    if author_name and len(author_name) > 0:
                        break
                except:
                    continue
            
            # å¦‚æœè¿˜æ²¡æœ‰ï¼Œå°è¯•ä»æ–‡æœ¬ä¸­æå–ï¼ˆé€šå¸¸åœ¨æ ‡é¢˜åé¢ï¼‰
            if not author_name:
                try:
                    all_text = element.text.strip()
                    lines = all_text.split('\n')
                    # é€šå¸¸ä½œè€…ååœ¨æ ‡é¢˜åé¢
                    found_title = False
                    for line in lines:
                        line = line.strip()
                        if found_title and line and not line.isdigit() and 'èµ' not in line and 'è¯„è®º' not in line:
                            author_name = line
                            break
                        if title and title in line:
                            found_title = True
                except:
                    pass
            
            # è·å–äº’åŠ¨æ•°æ® - ä½¿ç”¨å¤šç§æ–¹æ³•
            like_count = 0
            comment_count = 0
            collect_count = 0
            share_count = 0
            view_count = 0
            
            if self.debug:
                print(f"[DEBUG] å¼€å§‹æå–äº’åŠ¨æ•°æ®...")
            
            # æ–¹æ³•0: ä¼˜å…ˆä»é¡µé¢å…¨å±€æ•°æ®ä¸­æå–ï¼ˆæœ€é«˜æ•ˆï¼Œç±»ä¼¼æŠ–éŸ³çš„æ–¹æ³•ï¼‰
            if driver:
                try:
                    # ä»windowå¯¹è±¡ä¸­æå–æ•°æ®
                    scripts = [
                        "return window.__INITIAL_STATE__;",
                        "return window.__REDUX_STATE__;",
                        "return window._SSR_HYDRATED_DATA;",
                        "return window.__UNIVERSAL_DATA_FOR_HYDRATION__;",
                        "return window.__RENDER_DATA__;",
                        "return window.pageData;",
                        "return window.noteData;"
                    ]
                    for script in scripts:
                        try:
                            data = driver.execute_script(script)
                            if data:
                                # é€’å½’æœç´¢ç¬”è®°æ•°æ®
                                note_data = self._find_note_data_in_json(data, note_id)
                                if note_data:
                                    like_count = note_data.get('like_count', like_count) or like_count
                                    comment_count = note_data.get('comment_count', comment_count) or comment_count
                                    collect_count = note_data.get('collect_count', collect_count) or collect_count
                                    share_count = note_data.get('share_count', share_count) or share_count
                                    view_count = note_data.get('view_count', view_count) or view_count
                                    if self.debug and (like_count or comment_count or collect_count):
                                        print(f"[DEBUG] âœ“ ä»windowå¯¹è±¡æå–åˆ°äº’åŠ¨æ•°æ®")
                                    break
                        except:
                            continue
                except Exception as e:
                    if self.debug:
                        print(f"[DEBUG] ä»windowå¯¹è±¡æå–å¤±è´¥: {e}")
            
            # æ–¹æ³•1: ä»å…ƒç´ æ–‡æœ¬ä¸­æå–
            try:
                text = element.text
                if self.debug:
                    print(f"[DEBUG] å…ƒç´ æ–‡æœ¬: {text[:200]}")
                
                # è§£æç‚¹èµæ•° - å¤šç§æ¨¡å¼
                like_patterns = [
                    r'(\d+\.?\d*)[ä¸‡]?èµ',
                    r'(\d+\.?\d*)[ä¸‡]?ç‚¹èµ',
                    r'ç‚¹èµ[ï¼š:]\s*(\d+\.?\d*)[ä¸‡]?',
                    r'(\d+\.?\d*)[ä¸‡]?w?\s*èµ',
                    r'â¤\s*(\d+\.?\d*)[ä¸‡]?',
                    r'(\d+\.?\d*)[ä¸‡]?\s*â¤'
                ]
                for pattern in like_patterns:
                    like_match = re.search(pattern, text, re.IGNORECASE)
                    if like_match:
                        like_count = self._parse_count(like_match)
                        if self.debug:
                            print(f"[DEBUG] âœ“ ç‚¹èµæ•°: {like_count} (æ¨¡å¼: {pattern})")
                        break
                
                # è§£æè¯„è®ºæ•° - å¤šç§æ¨¡å¼
                comment_patterns = [
                    r'(\d+\.?\d*)[ä¸‡]?è¯„è®º',
                    r'(\d+\.?\d*)[ä¸‡]?æ¡è¯„è®º',
                    r'è¯„è®º[ï¼š:]\s*(\d+\.?\d*)[ä¸‡]?',
                    r'(\d+\.?\d*)[ä¸‡]?w?\s*è¯„è®º',
                    r'ğŸ’¬\s*(\d+\.?\d*)[ä¸‡]?',
                    r'(\d+\.?\d*)[ä¸‡]?\s*ğŸ’¬'
                ]
                for pattern in comment_patterns:
                    comment_match = re.search(pattern, text, re.IGNORECASE)
                    if comment_match:
                        comment_count = self._parse_count(comment_match)
                        if self.debug:
                            print(f"[DEBUG] âœ“ è¯„è®ºæ•°: {comment_count} (æ¨¡å¼: {pattern})")
                        break
                
                # è§£ææ”¶è—æ•° - å¤šç§æ¨¡å¼
                collect_patterns = [
                    r'(\d+\.?\d*)[ä¸‡]?æ”¶è—',
                    r'(\d+\.?\d*)[ä¸‡]?æ¬¡æ”¶è—',
                    r'æ”¶è—[ï¼š:]\s*(\d+\.?\d*)[ä¸‡]?',
                    r'(\d+\.?\d*)[ä¸‡]?w?\s*æ”¶è—',
                    r'â­\s*(\d+\.?\d*)[ä¸‡]?',
                    r'(\d+\.?\d*)[ä¸‡]?\s*â­',
                    r'ğŸ”–\s*(\d+\.?\d*)[ä¸‡]?'
                ]
                for pattern in collect_patterns:
                    collect_match = re.search(pattern, text, re.IGNORECASE)
                    if collect_match:
                        collect_count = self._parse_count(collect_match)
                        if self.debug:
                            print(f"[DEBUG] âœ“ æ”¶è—æ•°: {collect_count} (æ¨¡å¼: {pattern})")
                        break
                
                # è§£æåˆ†äº«æ•°ï¼ˆæ”¹è¿›ä»¥åŒ¹é…"ä¸‡"å•ä½ï¼‰
                share_patterns = [
                    r'(\d+\.?\d*)[ä¸‡w]?åˆ†äº«',
                    r'(\d+\.?\d*)[ä¸‡w]?æ¬¡åˆ†äº«',
                    r'åˆ†äº«[ï¼š:]\s*(\d+\.?\d*)[ä¸‡w]?',
                    r'(\d+\.?\d*)[ä¸‡w]?\s*åˆ†äº«',
                    r'(\d+\.?\d*)\s*ä¸‡\s*åˆ†äº«',
                    r'è½¬å‘[ï¼š:]\s*(\d+\.?\d*)[ä¸‡w]?',
                    r'(\d+\.?\d*)[ä¸‡w]?è½¬å‘'
                ]
                for pattern in share_patterns:
                    share_match = re.search(pattern, text, re.IGNORECASE)
                    if share_match:
                        share_count = self._parse_count(share_match)
                        if self.debug:
                            print(f"[DEBUG] âœ“ åˆ†äº«æ•°: {share_count} (æ¨¡å¼: {pattern})")
                        break
            except Exception as e:
                if self.debug:
                    print(f"[DEBUG] ä»æ–‡æœ¬æå–å¤±è´¥: {e}")
                pass
            
            # æ–¹æ³•2: å°è¯•ä»ç‰¹å®šçš„CSSé€‰æ‹©å™¨ä¸­æå–
            try:
                # å°è¯•æŸ¥æ‰¾ç‚¹èµæŒ‰é’®æˆ–æ˜¾ç¤ºç‚¹èµæ•°çš„å…ƒç´ 
                like_selectors = [
                    "[class*='like']",
                    "[class*='Like']",
                    "[class*='ç‚¹èµ']",
                    ".like-count",
                    "[data-like-count]"
                ]
                for selector in like_selectors:
                    try:
                        like_elem = element.find_element(By.CSS_SELECTOR, selector)
                        like_text = like_elem.text.strip()
                        if like_text and not like_count:
                            like_match = re.search(r'(\d+\.?\d*)[ä¸‡]?', like_text)
                            if like_match:
                                like_count = self._parse_count(like_match)
                                if self.debug:
                                    print(f"[DEBUG] âœ“ ä»é€‰æ‹©å™¨ '{selector}' è·å–ç‚¹èµæ•°: {like_count}")
                                break
                    except:
                        continue
                
                # å°è¯•æŸ¥æ‰¾è¯„è®ºæ•°
                comment_selectors = [
                    "[class*='comment']",
                    "[class*='Comment']",
                    "[class*='è¯„è®º']",
                    ".comment-count",
                    "[data-comment-count]"
                ]
                for selector in comment_selectors:
                    try:
                        comment_elem = element.find_element(By.CSS_SELECTOR, selector)
                        comment_text = comment_elem.text.strip()
                        if comment_text and not comment_count:
                            comment_match = re.search(r'(\d+\.?\d*)[ä¸‡]?', comment_text)
                            if comment_match:
                                comment_count = self._parse_count(comment_match)
                                if self.debug:
                                    print(f"[DEBUG] âœ“ ä»é€‰æ‹©å™¨ '{selector}' è·å–è¯„è®ºæ•°: {comment_count}")
                                break
                    except:
                        continue
                
                # å°è¯•æŸ¥æ‰¾æ”¶è—æ•°
                collect_selectors = [
                    "[class*='collect']",
                    "[class*='Collect']",
                    "[class*='æ”¶è—']",
                    ".collect-count",
                    "[data-collect-count]"
                ]
                for selector in collect_selectors:
                    try:
                        collect_elem = element.find_element(By.CSS_SELECTOR, selector)
                        collect_text = collect_elem.text.strip()
                        if collect_text and not collect_count:
                            collect_match = re.search(r'(\d+\.?\d*)[ä¸‡]?', collect_text)
                            if collect_match:
                                collect_count = self._parse_count(collect_match)
                                if self.debug:
                                    print(f"[DEBUG] âœ“ ä»é€‰æ‹©å™¨ '{selector}' è·å–æ”¶è—æ•°: {collect_count}")
                                break
                    except:
                        continue
            except Exception as e:
                if self.debug:
                    print(f"[DEBUG] ä»é€‰æ‹©å™¨æå–å¤±è´¥: {e}")
                pass
            
            # æ–¹æ³•3: ä»é¡µé¢æºç ä¸­æå–JSONæ•°æ®ï¼ˆå°çº¢ä¹¦é€šå¸¸ä¼šåœ¨é¡µé¢ä¸­åµŒå…¥JSONï¼‰
            if driver and (not like_count or not comment_count or not collect_count):
                try:
                    page_source = driver.page_source
                    
                    # æ–¹æ³•3.1: ä»é¡µé¢æºç ä¸­æå–å¸¦"ä¸‡"å•ä½çš„æ•°å­—
                    if not like_count:
                        wan_like_patterns = [
                            r'(\d+\.?\d*)\s*ä¸‡\s*èµ',
                            r'(\d+\.?\d*)\s*ä¸‡\s*ç‚¹èµ',
                            r'(\d+\.?\d*)[ä¸‡w]\s*èµ'
                        ]
                        for pattern in wan_like_patterns:
                            matches = re.findall(pattern, page_source)
                            if matches:
                                try:
                                    count = float(matches[0]) * 10000
                                    like_count = int(count)
                                    if self.debug:
                                        print(f"[DEBUG] âœ“ ä»é¡µé¢æºç æå–ç‚¹èµæ•°ï¼ˆä¸‡å•ä½ï¼‰: {like_count}")
                                    break
                                except:
                                    continue
                    
                    if not comment_count:
                        wan_comment_patterns = [
                            r'(\d+\.?\d*)\s*ä¸‡\s*è¯„è®º',
                            r'(\d+\.?\d*)[ä¸‡w]\s*è¯„è®º'
                        ]
                        for pattern in wan_comment_patterns:
                            matches = re.findall(pattern, page_source)
                            if matches:
                                try:
                                    count = float(matches[0]) * 10000
                                    comment_count = int(count)
                                    if self.debug:
                                        print(f"[DEBUG] âœ“ ä»é¡µé¢æºç æå–è¯„è®ºæ•°ï¼ˆä¸‡å•ä½ï¼‰: {comment_count}")
                                    break
                                except:
                                    continue
                    
                    if not collect_count:
                        wan_collect_patterns = [
                            r'(\d+\.?\d*)\s*ä¸‡\s*æ”¶è—',
                            r'(\d+\.?\d*)[ä¸‡w]\s*æ”¶è—'
                        ]
                        for pattern in wan_collect_patterns:
                            matches = re.findall(pattern, page_source)
                            if matches:
                                try:
                                    count = float(matches[0]) * 10000
                                    collect_count = int(count)
                                    if self.debug:
                                        print(f"[DEBUG] âœ“ ä»é¡µé¢æºç æå–æ”¶è—æ•°ï¼ˆä¸‡å•ä½ï¼‰: {collect_count}")
                                    break
                                except:
                                    continue
                    
                    # æ–¹æ³•3.2: ä»JSONæ•°æ®ä¸­æå–ï¼ˆå°çº¢ä¹¦é€šå¸¸ä¼šåœ¨scriptæ ‡ç­¾ä¸­åµŒå…¥JSONï¼‰
                    json_patterns = [
                        r'"liked_count":\s*(\d+)',
                        r'"likeCount":\s*(\d+)',
                        r'"likedCount":\s*(\d+)',
                        r'"comment_count":\s*(\d+)',
                        r'"commentCount":\s*(\d+)',
                        r'"collected_count":\s*(\d+)',
                        r'"collectCount":\s*(\d+)',
                        r'"collectedCount":\s*(\d+)',
                        r'"share_count":\s*(\d+)',
                        r'"shareCount":\s*(\d+)',
                        r'"viewed_count":\s*(\d+)',
                        r'"viewCount":\s*(\d+)'
                    ]
                    
                    # åœ¨ç¬”è®°IDé™„è¿‘æŸ¥æ‰¾æ•°æ®ï¼ˆæ›´å‡†ç¡®ï¼‰
                    if note_id:
                        # åœ¨åŒ…å«note_idçš„åŒºåŸŸæŸ¥æ‰¾
                        note_context_pattern = rf'{note_id}.*?{{.*?}}'
                        context_matches = re.finditer(note_context_pattern, page_source, re.DOTALL)
                        for context_match in context_matches:
                            context = context_match.group(0)
                            
                            # åœ¨ä¸Šä¸‹æ–‡ä¸­æŸ¥æ‰¾æ•°æ®
                            if not like_count:
                                like_matches = re.findall(r'"liked_count":\s*(\d+)|"likeCount":\s*(\d+)|"likedCount":\s*(\d+)', context)
                                if like_matches:
                                    for match in like_matches:
                                        count = int([x for x in match if x][0])
                                        if count > 0:
                                            like_count = count
                                            if self.debug:
                                                print(f"[DEBUG] âœ“ ä»JSONè·å–ç‚¹èµæ•°: {like_count}")
                                            break
                            
                            if not comment_count:
                                comment_matches = re.findall(r'"comment_count":\s*(\d+)|"commentCount":\s*(\d+)', context)
                                if comment_matches:
                                    for match in comment_matches:
                                        count = int([x for x in match if x][0])
                                        if count > 0:
                                            comment_count = count
                                            if self.debug:
                                                print(f"[DEBUG] âœ“ ä»JSONè·å–è¯„è®ºæ•°: {comment_count}")
                                            break
                            
                            if not collect_count:
                                collect_matches = re.findall(r'"collected_count":\s*(\d+)|"collectCount":\s*(\d+)|"collectedCount":\s*(\d+)', context)
                                if collect_matches:
                                    for match in collect_matches:
                                        count = int([x for x in match if x][0])
                                        if count > 0:
                                            collect_count = count
                                            if self.debug:
                                                print(f"[DEBUG] âœ“ ä»JSONè·å–æ”¶è—æ•°: {collect_count}")
                                            break
                            
                            if not share_count:
                                share_matches = re.findall(r'"share_count":\s*(\d+)|"shareCount":\s*(\d+)', context)
                                if share_matches:
                                    for match in share_matches:
                                        count = int([x for x in match if x][0])
                                        if count > 0:
                                            share_count = count
                                            if self.debug:
                                                print(f"[DEBUG] âœ“ ä»JSONè·å–åˆ†äº«æ•°: {share_count}")
                                            break
                            
                            if not view_count:
                                view_matches = re.findall(r'"viewed_count":\s*(\d+)|"viewCount":\s*(\d+)', context)
                                if view_matches:
                                    for match in view_matches:
                                        count = int([x for x in match if x][0])
                                        if count > 0:
                                            view_count = count
                                            if self.debug:
                                                print(f"[DEBUG] âœ“ ä»JSONè·å–æµè§ˆæ•°: {view_count}")
                                            break
                            
                            # å¦‚æœæ‰¾åˆ°äº†ä¸€äº›æ•°æ®ï¼Œå°±åœæ­¢æœç´¢
                            if like_count or comment_count or collect_count:
                                break
                except Exception as e:
                    if self.debug:
                        print(f"[DEBUG] ä»é¡µé¢æºç æå–JSONå¤±è´¥: {e}")
                    pass
            
            # æ–¹æ³•4: å¼ºåˆ¶è®¿é—®è¯¦æƒ…é¡µè·å–ï¼ˆå°çº¢ä¹¦æœç´¢é¡µé¢é€šå¸¸ä¸æ˜¾ç¤ºäº’åŠ¨æ•°æ®ï¼‰
            # å°çº¢ä¹¦æœç´¢é¡µé¢é€šå¸¸ä¸æ˜¾ç¤ºç‚¹èµã€è¯„è®ºã€æ”¶è—ç­‰æ•°æ®ï¼Œå¿…é¡»è®¿é—®è¯¦æƒ…é¡µ
            # å¼ºåˆ¶è®¿é—®è¯¦æƒ…é¡µï¼Œå› ä¸ºæœç´¢é¡µé¢å‡ ä¹ä¸å¯èƒ½æœ‰å®Œæ•´æ•°æ®
            if href and note_id and driver:
                if self.debug:
                    print(f"[DEBUG] å¼ºåˆ¶è®¿é—®è¯¦æƒ…é¡µè·å–å®Œæ•´äº’åŠ¨æ•°æ®: {href}")
                detail_data = self._get_note_detail_from_page(driver, href, note_id)
                if detail_data:
                    # ä¼˜å…ˆä½¿ç”¨è¯¦æƒ…é¡µçš„æ•°æ®ï¼ˆæ›´å‡†ç¡®ï¼‰ï¼Œè¦†ç›–ä¹‹å‰æå–çš„æ•°æ®
                    like_count = detail_data.get('like_count', 0) or like_count
                    comment_count = detail_data.get('comment_count', 0) or comment_count
                    collect_count = detail_data.get('collect_count', 0) or collect_count
                    share_count = detail_data.get('share_count', 0) or share_count
                    view_count = detail_data.get('view_count', 0) or view_count
                    if self.debug:
                        print(f"[DEBUG] âœ“ ä»è¯¦æƒ…é¡µè·å–æ•°æ® - ç‚¹èµ: {like_count}, è¯„è®º: {comment_count}, æ”¶è—: {collect_count}, åˆ†äº«: {share_count}, æµè§ˆ: {view_count}")
                else:
                    if self.debug:
                        print(f"[DEBUG] âš  è¯¦æƒ…é¡µè®¿é—®å¤±è´¥æˆ–æœªæå–åˆ°æ•°æ®")
            
            if self.debug:
                print(f"[DEBUG] æœ€ç»ˆæ•°æ® - ç‚¹èµ: {like_count}, è¯„è®º: {comment_count}, æ”¶è—: {collect_count}, åˆ†äº«: {share_count}")
            
            # æ£€æŸ¥æ ‡é¢˜æ˜¯å¦åŒ…å«å…³é”®è¯ï¼ˆæ”¾å®½æ¡ä»¶ï¼Œå¦‚æœæ ‡é¢˜æ˜¯é»˜è®¤å€¼åˆ™ä¸è¿‡æ»¤ï¼‰
            title_lower = title.lower() if title else ''
            if title != "å°çº¢ä¹¦ç¬”è®°":  # åªæœ‰çœŸå®æ ‡é¢˜æ‰è¿›è¡Œå…³é”®è¯è¿‡æ»¤
                keywords = ['åä¸º', 'huawei', 'é¸¿è’™', 'harmony', 'mate', 'pç³»åˆ—', 'nova', 'honor']
                matched_keywords = [kw for kw in keywords if kw in title_lower]
                if not matched_keywords:
                    if self.debug:
                        print(f"[DEBUG] âœ— æ ‡é¢˜ä¸åŒ…å«å…³é”®è¯: {title[:50]}")
                    return None
                if self.debug:
                    print(f"[DEBUG] âœ“ å…³é”®è¯åŒ¹é…: {matched_keywords}, æ ‡é¢˜: {title[:50]}")
            else:
                if self.debug:
                    print(f"[DEBUG] âš  ä½¿ç”¨é»˜è®¤æ ‡é¢˜ï¼Œè·³è¿‡å…³é”®è¯è¿‡æ»¤")
            
            return {
                'Post_ID': note_id,
                'Platform': 'XiaoHongShu',
                'Publish_Date': '',
                'Post_URL': href or f"https://www.xiaohongshu.com/explore/{note_id}",
                'Author_ID': '',
                'Author_Name': author_name,
                'Title': title,
                'Content': title,  # æœç´¢é¡µé¢é€šå¸¸åªæœ‰æ ‡é¢˜
                'Tags': '',
                'Like_Count': like_count,
                'Comment_Count': comment_count,
                'Collect_Count': collect_count,
                'Share_Count': share_count,
                'View_Count': view_count
            }
        except Exception as e:
            if self.debug:
                print(f"[DEBUG] âœ— è§£æå‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
            return None
    
    def _get_note_detail_from_page(self, driver, url: str, note_id: str) -> Dict:
        """
        è®¿é—®ç¬”è®°è¯¦æƒ…é¡µè·å–äº’åŠ¨æ•°æ®
        """
        try:
            if self.debug:
                print(f"[DEBUG] è®¿é—®è¯¦æƒ…é¡µ: {url}")
            
            # åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€è¯¦æƒ…é¡µ
            original_window = driver.current_window_handle
            driver.execute_script(f"window.open('{url}', '_blank');")
            time.sleep(2)
            
            # åˆ‡æ¢åˆ°æ–°æ ‡ç­¾é¡µ
            windows = driver.window_handles
            if len(windows) > 1:
                driver.switch_to.window(windows[-1])
                time.sleep(5)  # ç­‰å¾…é¡µé¢å®Œå…¨åŠ è½½ï¼Œå¢åŠ ç­‰å¾…æ—¶é—´
                
                # ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½
                try:
                    from selenium.webdriver.common.by import By
                    from selenium.webdriver.support.ui import WebDriverWait
                    from selenium.webdriver.support import expected_conditions as EC
                    WebDriverWait(driver, 10).until(
                        EC.presence_of_element_located((By.TAG_NAME, "body"))
                    )
                except:
                    pass
                
                # å°è¯•æå–äº’åŠ¨æ•°æ®
                detail_data = {}
                try:
                    # æ–¹æ³•1: ä»windowå¯¹è±¡ä¸­æå–ï¼ˆè¯¦æƒ…é¡µé€šå¸¸ä¼šæœ‰å®Œæ•´æ•°æ®ï¼‰
                    scripts = [
                            "return window.__INITIAL_STATE__;",
                            "return window.__REDUX_STATE__;",
                            "return window._SSR_HYDRATED_DATA;",
                            "return window.__UNIVERSAL_DATA_FOR_HYDRATION__;",
                            "return window.noteDetail;",
                            "return window.noteData;",
                            "return window.pageData;",
                            "return window.__NEXT_DATA__;"
                    ]
                    for script in scripts:
                        try:
                            data = driver.execute_script(script)
                            if data:
                                note_data = self._find_note_data_in_json(data, note_id)
                                if note_data:
                                    detail_data.update(note_data)
                                    if self.debug:
                                        print(f"[DEBUG] âœ“ ä»è¯¦æƒ…é¡µwindowå¯¹è±¡æå–åˆ°æ•°æ®: {note_data}")
                                    # å¦‚æœè·å–åˆ°å®Œæ•´æ•°æ®ï¼Œå°±ä¸å†å°è¯•å…¶ä»–æ–¹æ³•
                                    if detail_data.get('like_count') and detail_data.get('comment_count'):
                                        break
                        except Exception as e:
                            if self.debug:
                                print(f"[DEBUG] windowå¯¹è±¡æå–å¤±è´¥ ({script[:30]}...): {str(e)[:50]}")
                            continue
                    
                    # æ–¹æ³•2: ä»scriptæ ‡ç­¾ä¸­æå–JSON
                    if not detail_data or not detail_data.get('like_count'):
                            try:
                                from selenium.webdriver.common.by import By
                                script_elements = driver.find_elements(By.TAG_NAME, "script")
                                for script in script_elements:
                                    try:
                                        script_text = script.get_attribute('innerHTML') or script.get_attribute('textContent')
                                        if not script_text or len(script_text) < 100:
                                            continue
                                        
                                        # æŸ¥æ‰¾åŒ…å«äº’åŠ¨æ•°æ®çš„JSON
                                        if 'liked_count' in script_text or 'interact_info' in script_text or 'noteDetail' in script_text:
                                            # å°è¯•æå–JSONå¯¹è±¡ - å¤šç§æ¨¡å¼
                                            json_patterns = [
                                                r'{"noteDetail"[^}]*?"interact_info"[^}]*?}}',
                                                r'"interact_info"[^}]*?}',
                                                r'{"noteId":"[^"]*"[^}]*?"interact_info"[^}]*?}}',
                                                r'"liked_count":\s*(\d+)[^}]*"comment_count":\s*(\d+)[^}]*"collected_count":\s*(\d+)',
                                            ]
                                            
                                            for json_pattern in json_patterns:
                                                json_match = re.search(json_pattern, script_text, re.DOTALL)
                                                if json_match:
                                                    json_str = json_match.group(0)
                                                    
                                                    # æå–å„ä¸ªå­—æ®µ
                                                    like_match = re.search(r'"liked_count":\s*(\d+)', json_str)
                                                    comment_match = re.search(r'"comment_count":\s*(\d+)', json_str)
                                                    collect_match = re.search(r'"collected_count":\s*(\d+)', json_str)
                                                    share_match = re.search(r'"share_count":\s*(\d+)', json_str)
                                                    view_match = re.search(r'"viewed_count":\s*(\d+)', json_str)
                                                    
                                                    if like_match and not detail_data.get('like_count'):
                                                        detail_data['like_count'] = int(like_match.group(1))
                                                    if comment_match and not detail_data.get('comment_count'):
                                                        detail_data['comment_count'] = int(comment_match.group(1))
                                                    if collect_match and not detail_data.get('collect_count'):
                                                        detail_data['collect_count'] = int(collect_match.group(1))
                                                    if share_match and not detail_data.get('share_count'):
                                                        detail_data['share_count'] = int(share_match.group(1))
                                                    if view_match and not detail_data.get('view_count'):
                                                        detail_data['view_count'] = int(view_match.group(1))
                                                    
                                                    if detail_data and self.debug:
                                                        print(f"[DEBUG] âœ“ ä»scriptæ ‡ç­¾æå–åˆ°æ•°æ®: {detail_data}")
                                                    break
                                            
                                            if detail_data.get('like_count'):
                                                break
                                    except Exception as e:
                                        if self.debug:
                                            print(f"[DEBUG] scriptæ ‡ç­¾æå–å¤±è´¥: {str(e)[:50]}")
                                        continue
                            except Exception as e:
                                if self.debug:
                                    print(f"[DEBUG] ä»scriptæ ‡ç­¾æå–å¤±è´¥: {e}")
                    
                    # æ–¹æ³•3: ä»é¡µé¢å…ƒç´ ä¸­æå–ï¼ˆå°çº¢ä¹¦è¯¦æƒ…é¡µé€šå¸¸ä¼šåœ¨é¡µé¢ä¸Šæ˜¾ç¤ºè¿™äº›æ•°æ®ï¼‰
                    if not detail_data or not detail_data.get('like_count'):
                            try:
                                from selenium.webdriver.common.by import By
                                
                                # å°è¯•ä»é¡µé¢å…ƒç´ ä¸­æŸ¥æ‰¾äº’åŠ¨æ•°æ®
                                # å°çº¢ä¹¦è¯¦æƒ…é¡µé€šå¸¸ä¼šæ˜¾ç¤ºç‚¹èµã€è¯„è®ºã€æ”¶è—ç­‰æ•°æ®
                                interact_selectors = [
                                    "[class*='like']",
                                    "[class*='comment']",
                                    "[class*='collect']",
                                    "[class*='interact']",
                                    "[class*='stats']",
                                    "[data-v-]"
                                ]
                                
                                for selector in interact_selectors:
                                    try:
                                        elements = driver.find_elements(By.CSS_SELECTOR, selector)
                                        for elem in elements:
                                            text = elem.text.strip()
                                            if not text:
                                                continue
                                            
                                            # ä»æ–‡æœ¬ä¸­æå–æ•°å­—
                                            if 'èµ' in text or 'like' in text.lower():
                                                match = re.search(r'(\d+\.?\d*)[ä¸‡w]?', text)
                                                if match and not detail_data.get('like_count'):
                                                    detail_data['like_count'] = self._parse_count(match)
                                                    if self.debug:
                                                        print(f"[DEBUG] âœ“ ä»å…ƒç´ æå–ç‚¹èµæ•°: {detail_data['like_count']}")
                                            
                                            if 'è¯„è®º' in text or 'comment' in text.lower():
                                                match = re.search(r'(\d+\.?\d*)[ä¸‡w]?', text)
                                                if match and not detail_data.get('comment_count'):
                                                    detail_data['comment_count'] = self._parse_count(match)
                                                    if self.debug:
                                                        print(f"[DEBUG] âœ“ ä»å…ƒç´ æå–è¯„è®ºæ•°: {detail_data['comment_count']}")
                                            
                                            if 'æ”¶è—' in text or 'collect' in text.lower():
                                                match = re.search(r'(\d+\.?\d*)[ä¸‡w]?', text)
                                                if match and not detail_data.get('collect_count'):
                                                    detail_data['collect_count'] = self._parse_count(match)
                                                    if self.debug:
                                                        print(f"[DEBUG] âœ“ ä»å…ƒç´ æå–æ”¶è—æ•°: {detail_data['collect_count']}")
                                            
                                            if 'åˆ†äº«' in text or 'share' in text.lower():
                                                match = re.search(r'(\d+\.?\d*)[ä¸‡w]?', text)
                                                if match and not detail_data.get('share_count'):
                                                    detail_data['share_count'] = self._parse_count(match)
                                                    if self.debug:
                                                        print(f"[DEBUG] âœ“ ä»å…ƒç´ æå–åˆ†äº«æ•°: {detail_data['share_count']}")
                                            
                                            # å¦‚æœå·²ç»æ‰¾åˆ°äº†æ‰€æœ‰æ•°æ®ï¼Œåœæ­¢æœç´¢
                                            if detail_data.get('like_count') and detail_data.get('comment_count') and detail_data.get('collect_count'):
                                                break
                                    except:
                                        continue
                            except Exception as e:
                                if self.debug:
                                    print(f"[DEBUG] ä»é¡µé¢å…ƒç´ æå–å¤±è´¥: {e}")
                    
                    # æ–¹æ³•4: ä»é¡µé¢æºç HTMLä¸­æå–ï¼ˆæœ€åçš„æ‰‹æ®µï¼‰
                    if not detail_data or not detail_data.get('like_count'):
                            page_text = driver.page_source
                            
                            # ä»é¡µé¢æºç ä¸­æå–æ•°æ®
                            patterns = {
                                'like_count': [
                                    r'"liked_count":\s*(\d+)',
                                    r'"likeCount":\s*(\d+)',
                                    r'"likedCount":\s*(\d+)',
                                    r'(\d+\.?\d*)\s*ä¸‡\s*èµ',
                                    r'(\d+\.?\d*)[ä¸‡w]\s*èµ',
                                    r'ç‚¹èµ[ï¼š:]\s*(\d+\.?\d*)[ä¸‡w]?',
                                    r'(\d+\.?\d*)[ä¸‡w]?èµ'
                                ],
                                'comment_count': [
                                    r'"comment_count":\s*(\d+)',
                                    r'"commentCount":\s*(\d+)',
                                    r'(\d+\.?\d*)\s*ä¸‡\s*è¯„è®º',
                                    r'(\d+\.?\d*)[ä¸‡w]\s*è¯„è®º',
                                    r'è¯„è®º[ï¼š:]\s*(\d+\.?\d*)[ä¸‡w]?',
                                    r'(\d+\.?\d*)[ä¸‡w]?è¯„è®º'
                                ],
                                'collect_count': [
                                    r'"collected_count":\s*(\d+)',
                                    r'"collectCount":\s*(\d+)',
                                    r'"collectedCount":\s*(\d+)',
                                    r'(\d+\.?\d*)\s*ä¸‡\s*æ”¶è—',
                                    r'(\d+\.?\d*)[ä¸‡w]\s*æ”¶è—',
                                    r'æ”¶è—[ï¼š:]\s*(\d+\.?\d*)[ä¸‡w]?',
                                    r'(\d+\.?\d*)[ä¸‡w]?æ”¶è—'
                                ],
                                'share_count': [
                                    r'"share_count":\s*(\d+)',
                                    r'"shareCount":\s*(\d+)',
                                    r'(\d+\.?\d*)\s*ä¸‡\s*åˆ†äº«',
                                    r'(\d+\.?\d*)[ä¸‡w]\s*åˆ†äº«',
                                    r'åˆ†äº«[ï¼š:]\s*(\d+\.?\d*)[ä¸‡w]?',
                                    r'(\d+\.?\d*)[ä¸‡w]?åˆ†äº«'
                                ],
                                'view_count': [
                                    r'"viewed_count":\s*(\d+)',
                                    r'"viewCount":\s*(\d+)',
                                    r'(\d+\.?\d*)\s*ä¸‡\s*æµè§ˆ',
                                    r'(\d+\.?\d*)[ä¸‡w]\s*æµè§ˆ'
                                ]
                            }
                            
                            for key, pattern_list in patterns.items():
                                if detail_data.get(key):  # å¦‚æœå·²ç»æœ‰æ•°æ®ï¼Œè·³è¿‡
                                    continue
                                for pattern in pattern_list:
                                    match = re.search(pattern, page_text)
                                    if match:
                                        try:
                                            # æ£€æŸ¥æ˜¯å¦åŒ…å«"ä¸‡"
                                            full_text = match.group(0)
                                            count_str = match.group(1)
                                            count = float(count_str)
                                            
                                            if 'ä¸‡' in full_text or 'w' in full_text.lower():
                                                count = int(count * 10000)
                                            else:
                                                count = int(count)
                                            
                                            detail_data[key] = count
                                            if self.debug:
                                                print(f"[DEBUG] âœ“ ä»è¯¦æƒ…é¡µé¡µé¢æºç æå–{key}: {count}")
                                            break
                                        except Exception as e:
                                            if self.debug:
                                                print(f"[DEBUG] è§£æ{key}å¤±è´¥: {e}")
                                            continue
                    
                    # å¦‚æœè¿˜æ˜¯æ²¡æœ‰æ•°æ®ï¼Œæ‰“å°é¡µé¢æºç çš„ä¸€éƒ¨åˆ†ç”¨äºè°ƒè¯•
                    if not detail_data and self.debug:
                        page_text_sample = driver.page_source[:2000]  # å‰2000ä¸ªå­—ç¬¦
                        print(f"[DEBUG] âš  æœªæ‰¾åˆ°äº’åŠ¨æ•°æ®ï¼Œé¡µé¢æºç ç¤ºä¾‹:\n{page_text_sample}")
                except Exception as e:
                    if self.debug:
                        print(f"[DEBUG] ä»è¯¦æƒ…é¡µæå–æ•°æ®å¤±è´¥: {e}")
                
                # å…³é—­è¯¦æƒ…é¡µæ ‡ç­¾ï¼Œåˆ‡æ¢å›åŸçª—å£
                driver.close()
                driver.switch_to.window(original_window)
                time.sleep(1)
                
                return detail_data
        except Exception as e:
            if self.debug:
                print(f"[DEBUG] è®¿é—®è¯¦æƒ…é¡µå¤±è´¥: {e}")
            # ç¡®ä¿åˆ‡æ¢å›åŸçª—å£
            try:
                driver.switch_to.window(original_window)
            except:
                pass
            return {}
    
    def _save_cookies(self, driver) -> bool:
        """
        ä¿å­˜Cookieåˆ°æ–‡ä»¶
        """
        try:
            import pickle
            cookies = driver.get_cookies()
            with open(self.cookie_file, 'wb') as f:
                pickle.dump(cookies, f)
            if self.debug:
                print(f"[DEBUG] Cookieå·²ä¿å­˜åˆ°: {self.cookie_file}")
            return True
        except Exception as e:
            if self.debug:
                print(f"[DEBUG] ä¿å­˜Cookieå¤±è´¥: {e}")
            return False
    
    def _load_cookies(self, driver) -> bool:
        """
        ä»æ–‡ä»¶åŠ è½½Cookie
        """
        try:
            import pickle
            import os
            if not os.path.exists(self.cookie_file):
                return False
            
            with open(self.cookie_file, 'rb') as f:
                cookies = pickle.load(f)
            
            # å…ˆè®¿é—®åŸŸåï¼Œç„¶åæ·»åŠ Cookie
            driver.get("https://www.xiaohongshu.com")
            time.sleep(1)
            
            for cookie in cookies:
                try:
                    # ç§»é™¤å¯èƒ½å¯¼è‡´é—®é¢˜çš„å­—æ®µ
                    cookie.pop('domain', None)
                    cookie.pop('expiry', None)
                    driver.add_cookie(cookie)
                except Exception as e:
                    if self.debug:
                        print(f"[DEBUG] æ·»åŠ Cookieå¤±è´¥: {e}")
                    continue
            
            if self.debug:
                print(f"[DEBUG] Cookieå·²åŠ è½½: {len(cookies)} ä¸ª")
            return True
        except Exception as e:
            if self.debug:
                print(f"[DEBUG] åŠ è½½Cookieå¤±è´¥: {e}")
            return False
    
    def get_comments(self, note_id: str, note_url: str, driver=None, top_n: int = 5) -> List[Dict]:
        """
        è·å–ç¬”è®°çš„çƒ­é—¨è¯„è®ºï¼ˆæŒ‰ç‚¹èµæ•°æ’åºï¼Œå–å‰Næ¡ï¼‰
        :param note_id: ç¬”è®°ID
        :param note_url: ç¬”è®°URL
        :param driver: Selenium driverï¼ˆå¿…éœ€ï¼‰
        :param top_n: è·å–å‰Næ¡è¯„è®º
        :return: è¯„è®ºåˆ—è¡¨
        """
        comments = []
        try:
            if not driver:
                if self.debug:
                    print(f"[DEBUG] âš  éœ€è¦driveræ¥è·å–å°çº¢ä¹¦è¯„è®º")
                return comments
            
            if self.debug:
                print(f"[DEBUG] å¼€å§‹è·å–å°çº¢ä¹¦è¯„è®º: {note_url}")
            
            # è®¿é—®ç¬”è®°è¯¦æƒ…é¡µ
            driver.get(note_url)
            time.sleep(5)  # ç­‰å¾…é¡µé¢åŠ è½½
            
            # ç­‰å¾…é¡µé¢å†…å®¹åŠ è½½
            try:
                from selenium.webdriver.common.by import By
                from selenium.webdriver.support.ui import WebDriverWait
                from selenium.webdriver.support import expected_conditions as EC
                WebDriverWait(driver, 10).until(
                    EC.presence_of_element_located((By.TAG_NAME, "body"))
                )
            except:
                pass
            
            # å°è¯•æ»šåŠ¨åˆ°è¯„è®ºåŒº
            try:
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(3)
                # å†æ»šåŠ¨ä¸€ç‚¹ï¼Œç¡®ä¿è¯„è®ºåŒºåŠ è½½
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
            except:
                pass
            
            # æ–¹æ³•1: ä»windowå¯¹è±¡ä¸­æå–è¯„è®ºæ•°æ®ï¼ˆæœ€å‡†ç¡®ï¼‰
            try:
                scripts = [
                    "return window.__INITIAL_STATE__;",
                    "return window.__REDUX_STATE__;",
                    "return window._SSR_HYDRATED_DATA;",
                    "return window.noteDetail;",
                    "return window.commentsData;",
                    "return window.pageData;"
                ]
                
                for script in scripts:
                    try:
                        data = driver.execute_script(script)
                        if data:
                            # é€’å½’æœç´¢è¯„è®ºæ•°æ®
                            comment_list = self._find_comments_in_json(data)
                            if comment_list:
                                # æŒ‰ç‚¹èµæ•°æ’åº
                                comment_list.sort(key=lambda x: x.get('like_count', 0), reverse=True)
                                # å–å‰Næ¡
                                for i, comment_data in enumerate(comment_list[:top_n]):
                                    comments.append({
                                        'Post_ID': note_id,
                                        'Comment_ID': comment_data.get('comment_id', f"{note_id}_comment_{i+1}"),
                                        'Comment_Content': comment_data.get('content', ''),
                                        'Comment_Author': comment_data.get('author', ''),
                                        'Comment_Like_Count': comment_data.get('like_count', 0),
                                        'Comment_Time': comment_data.get('time', ''),
                                        'Platform': 'XiaoHongShu'
                                    })
                                if self.debug:
                                    print(f"[DEBUG] âœ“ ä»windowå¯¹è±¡è·å–åˆ° {len(comments)} æ¡è¯„è®º")
                                break
                    except Exception as e:
                        if self.debug:
                            print(f"[DEBUG] windowå¯¹è±¡æå–è¯„è®ºå¤±è´¥ ({script[:30]}...): {str(e)[:50]}")
                        continue
            except Exception as e:
                if self.debug:
                    print(f"[DEBUG] ä»windowå¯¹è±¡æå–è¯„è®ºå¤±è´¥: {e}")
            
            # æ–¹æ³•2: ä»é¡µé¢æºç scriptæ ‡ç­¾ä¸­æå–è¯„è®ºJSON
            if not comments:
                try:
                    from selenium.webdriver.common.by import By
                    page_source = driver.page_source
                    
                    # æŸ¥æ‰¾è¯„è®ºç›¸å…³çš„JSONæ•°æ®
                    comment_patterns = [
                        r'"comments":\s*\[(.*?)\]',
                        r'"commentList":\s*\[(.*?)\]',
                        r'"items":\s*\[(.*?)\]',
                        r'"comment_list":\s*\[(.*?)\]',
                    ]
                    
                    for pattern in comment_patterns:
                        matches = re.finditer(pattern, page_source, re.DOTALL)
                        for match in matches:
                            comments_json_str = match.group(1)
                            if not comments_json_str or len(comments_json_str) < 10:
                                continue
                            
                            # å°è¯•æå–å•ä¸ªè¯„è®º
                            single_comment_pattern = r'{"comment_id"[^}]*?"content":"([^"]+)"[^}]*?"user_name":"([^"]+)"[^}]*?"liked_count":(\d+)'
                            comment_matches = re.finditer(single_comment_pattern, comments_json_str, re.DOTALL)
                            
                            comment_list = []
                            for cm in comment_matches:
                                try:
                                    comment_list.append({
                                        'comment_id': '',
                                        'content': cm.group(1),
                                        'author': cm.group(2),
                                        'like_count': int(cm.group(3)),
                                        'time': ''
                                    })
                                except:
                                    continue
                            
                            if comment_list:
                                # æŒ‰ç‚¹èµæ•°æ’åº
                                comment_list.sort(key=lambda x: x['like_count'], reverse=True)
                                # å–å‰Næ¡
                                for i, comment_data in enumerate(comment_list[:top_n]):
                                    comments.append({
                                        'Post_ID': note_id,
                                        'Comment_ID': f"{note_id}_comment_{i+1}",
                                        'Comment_Content': comment_data['content'],
                                        'Comment_Author': comment_data['author'],
                                        'Comment_Like_Count': comment_data['like_count'],
                                        'Comment_Time': comment_data['time'],
                                        'Platform': 'XiaoHongShu'
                                    })
                                if self.debug:
                                    print(f"[DEBUG] âœ“ ä»JSONè·å–åˆ° {len(comments)} æ¡è¯„è®º")
                                break
                except Exception as e:
                    if self.debug:
                        print(f"[DEBUG] ä»JSONæå–è¯„è®ºå¤±è´¥: {e}")
            
            # æ–¹æ³•3: ä»é¡µé¢å…ƒç´ ä¸­æå–è¯„è®ºï¼ˆæœ€å¯é çš„æ–¹æ³•ï¼‰
            if not comments:
                try:
                    from selenium.webdriver.common.by import By
                    from selenium.webdriver.support.ui import WebDriverWait
                    from selenium.webdriver.support import expected_conditions as EC
                    
                    # ç­‰å¾…è¯„è®ºåŒºåŸŸåŠ è½½
                    try:
                        WebDriverWait(driver, 5).until(
                            EC.presence_of_element_located((By.CSS_SELECTOR, "[class*='comment'], [class*='Comment']"))
                        )
                    except:
                        pass
                    
                    comment_selectors = [
                        ".comment-item",
                        "[class*='comment-item']",
                        "[class*='CommentItem']",
                        "[class*='comment']",
                        "[class*='Comment']",
                        ".note-comment-item",
                        "[data-v-]",
                        "li[class*='comment']"
                    ]
                    
                    comment_elements = []
                    for selector in comment_selectors:
                        try:
                            elements = driver.find_elements(By.CSS_SELECTOR, selector)
                            if elements and len(elements) > 0:
                                comment_elements = elements
                                if self.debug:
                                    print(f"[DEBUG] âœ“ ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(elements)} ä¸ªè¯„è®ºå…ƒç´ ")
                                break
                        except:
                            continue
                    
                    if comment_elements:
                        comment_data_list = []
                        for elem in comment_elements[:30]:  # æœ€å¤šå–30æ¡ï¼Œç„¶åæ’åº
                            try:
                                # æå–è¯„è®ºå†…å®¹
                                content = ''
                                try:
                                    content_elem = elem.find_element(By.CSS_SELECTOR, "[class*='content'], [class*='text'], p, span")
                                    content = content_elem.text.strip()
                                except:
                                    # å¦‚æœæ‰¾ä¸åˆ°ç‰¹å®šå…ƒç´ ï¼Œä½¿ç”¨æ•´ä¸ªå…ƒç´ çš„æ–‡æœ¬
                                    content = elem.text.strip()
                                    # å°è¯•ä»æ–‡æœ¬ä¸­æå–è¯„è®ºå†…å®¹ï¼ˆæ’é™¤ä½œè€…åå’Œç‚¹èµæ•°ï¼‰
                                    lines = content.split('\n')
                                    for line in lines:
                                        line = line.strip()
                                        if line and len(line) > 5 and 'èµ' not in line and 'è¯„è®º' not in line:
                                            content = line
                                            break
                                
                                # æå–ç‚¹èµæ•°
                                like_count = 0
                                try:
                                    like_elem = elem.find_elements(By.CSS_SELECTOR, "[class*='like'], [class*='Like'], [class*='ç‚¹èµ']")
                                    if like_elem:
                                        like_text = like_elem[0].text.strip()
                                        like_match = re.search(r'(\d+\.?\d*)[ä¸‡w]?', like_text)
                                        if like_match:
                                            like_count = self._parse_count(like_match)
                                except:
                                    # ä»å…ƒç´ æ–‡æœ¬ä¸­æå–
                                    elem_text = elem.text
                                    like_match = re.search(r'(\d+\.?\d*)[ä¸‡w]?\s*èµ', elem_text)
                                    if like_match:
                                        like_count = self._parse_count(like_match)
                                
                                # æå–ä½œè€…
                                author = ''
                                try:
                                    author_elem = elem.find_elements(By.CSS_SELECTOR, "[class*='author'], [class*='user'], [class*='name'], [class*='nickname']")
                                    if author_elem:
                                        author = author_elem[0].text.strip()
                                        # è¿‡æ»¤æ‰æ•°å­—å’Œç‰¹æ®Šå­—ç¬¦
                                        if author and not author.isdigit() and len(author) < 50:
                                            pass  # ä¿ç•™
                                        else:
                                            author = ''
                                except:
                                    pass
                                
                                # å¦‚æœæ²¡æœ‰ä½œè€…ï¼Œå°è¯•ä»æ–‡æœ¬ç¬¬ä¸€è¡Œæå–
                                if not author:
                                    elem_text = elem.text
                                    lines = elem_text.split('\n')
                                    for line in lines[:3]:  # åªæ£€æŸ¥å‰3è¡Œ
                                        line = line.strip()
                                        if line and not line.isdigit() and 'èµ' not in line and 'è¯„è®º' not in line and len(line) < 30:
                                            author = line
                                            break
                                
                                if content and len(content) > 3:  # ç¡®ä¿æœ‰å®é™…çš„è¯„è®ºå†…å®¹
                                    comment_data_list.append({
                                        'content': content[:500],  # é™åˆ¶é•¿åº¦
                                        'like_count': like_count,
                                        'author': author[:50]  # é™åˆ¶é•¿åº¦
                                    })
                            except Exception as e:
                                if self.debug:
                                    print(f"[DEBUG] è§£æå•æ¡è¯„è®ºå¤±è´¥: {e}")
                                continue
                        
                        if comment_data_list:
                            # æŒ‰ç‚¹èµæ•°æ’åº
                            comment_data_list.sort(key=lambda x: x['like_count'], reverse=True)
                            
                            # å–å‰Næ¡
                            for i, comment_data in enumerate(comment_data_list[:top_n]):
                                comments.append({
                                    'Post_ID': note_id,
                                    'Comment_ID': f"{note_id}_comment_{i+1}",
                                    'Comment_Content': comment_data['content'],
                                    'Comment_Author': comment_data['author'],
                                    'Comment_Like_Count': comment_data['like_count'],
                                    'Comment_Time': '',
                                    'Platform': 'XiaoHongShu'
                                })
                            
                            if self.debug:
                                print(f"[DEBUG] âœ“ ä»é¡µé¢å…ƒç´ è·å–åˆ° {len(comments)} æ¡å°çº¢ä¹¦è¯„è®º")
                        else:
                            if self.debug:
                                print(f"[DEBUG] âš  æ‰¾åˆ°äº†è¯„è®ºå…ƒç´ ä½†æ— æ³•æå–è¯„è®ºå†…å®¹")
                    else:
                        if self.debug:
                            print(f"[DEBUG] âš  æœªæ‰¾åˆ°è¯„è®ºå…ƒç´ ï¼Œå¯èƒ½æ²¡æœ‰è¯„è®ºæˆ–éœ€è¦ç™»å½•")
                except Exception as e:
                    if self.debug:
                        print(f"[DEBUG] ä»é¡µé¢å…ƒç´ æå–è¯„è®ºå¤±è´¥: {e}")
                    import traceback
                    traceback.print_exc()
        except Exception as e:
            if self.debug:
                print(f"[DEBUG] å°çº¢ä¹¦è¯„è®ºçˆ¬å–å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
        
        return comments
    
    def _find_comments_in_json(self, data, path="") -> List[Dict]:
        """
        é€’å½’æœç´¢JSONæ•°æ®ä¸­çš„è¯„è®ºä¿¡æ¯
        """
        comments = []
        try:
            if isinstance(data, dict):
                # æ£€æŸ¥æ˜¯å¦åŒ…å«è¯„è®ºæ•°æ®
                if 'comments' in data or 'commentList' in data or 'items' in data:
                    comment_list = data.get('comments') or data.get('commentList') or data.get('items', [])
                    if isinstance(comment_list, list):
                        for comment in comment_list:
                            if isinstance(comment, dict):
                                comment_data = {
                                    'comment_id': str(comment.get('comment_id', comment.get('id', ''))),
                                    'content': comment.get('content', comment.get('text', comment.get('comment', ''))),
                                    'author': comment.get('user_name', comment.get('author', comment.get('nickname', ''))),
                                    'like_count': comment.get('liked_count', comment.get('like_count', comment.get('likeCount', 0))),
                                    'time': comment.get('create_time', comment.get('time', ''))
                                }
                                if comment_data['content']:
                                    comments.append(comment_data)
                
                # é€’å½’æœç´¢
                for key, value in data.items():
                    if isinstance(value, (dict, list)):
                        nested_comments = self._find_comments_in_json(value, f"{path}.{key}")
                        comments.extend(nested_comments)
            
            elif isinstance(data, list):
                for i, item in enumerate(data):
                    if isinstance(item, (dict, list)):
                        nested_comments = self._find_comments_in_json(item, f"{path}[{i}]")
                        comments.extend(nested_comments)
        except:
            pass
        
        return comments
    
    def _parse_count(self, match) -> int:
        """è§£ææ•°é‡ï¼ˆæ”¯æŒä¸‡å•ä½ï¼‰"""
        if not match:
            return 0
        count_str = match.group(1)
        try:
            count = float(count_str)
            if 'ä¸‡' in match.group(0):
                count = int(count * 10000)
            return int(count)
        except:
            return 0
    
    def crawl(self, keyword: str = "åä¸º", max_pages: int = 10, use_selenium: bool = True) -> List[Dict]:
        """
        çˆ¬å–å¤šé¡µæ•°æ®
        :param keyword: æœç´¢å…³é”®è¯
        :param max_pages: æœ€å¤§çˆ¬å–é¡µæ•°
        :param use_selenium: æ˜¯å¦ä½¿ç”¨seleniumï¼ˆæ¨èï¼‰
        :return: æ‰€æœ‰ç¬”è®°æ•°æ®
        """
        if use_selenium:
            return self.crawl_with_selenium(keyword, max_pages)
        else:
            all_notes = []
            for page in range(1, max_pages + 1):
                print(f"æ­£åœ¨çˆ¬å–å°çº¢ä¹¦ç¬¬ {page} é¡µ...")
                notes = self.search_notes(keyword, page=page)
                if not notes:
                    break
                all_notes.extend(notes)
                time.sleep(random.uniform(2, 4))
            return all_notes


if __name__ == "__main__":
    spider = XiaohongshuSpider()
    # æµ‹è¯•çˆ¬å–ï¼ˆä½¿ç”¨seleniumï¼‰
    results = spider.crawl(keyword="åä¸º", max_pages=2, use_selenium=True)
    print(f"\næµ‹è¯•ç»“æœ: å…±è·å– {len(results)} æ¡æ•°æ®")
    if results:
        print("\nç¬¬ä¸€æ¡æ•°æ®ç¤ºä¾‹:")
        print(json.dumps(results[0], ensure_ascii=False, indent=2))

