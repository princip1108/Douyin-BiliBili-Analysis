{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "DATA_PATH = \"./data\"\n",
    "with open(DATA_PATH+r\"\\stopwords.txt\",'r') as file:\n",
    "    stopwords=file.read()\n",
    "\n",
    "amazon_df=pd.read_csv(DATA_PATH+r\"\\Amazon.csv\")\n",
    "google_df=pd.read_csv(DATA_PATH+r\"\\Google.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "perfectMap_df=pd.read_csv(DATA_PATH+r\"\\Amazon_Google_perfectMapping.csv\")\n",
    "perfectMap=[]\n",
    "def buildPerfectMap(x): perfectMap.append((x['idAmazon'],x['idGoogleBase']))\n",
    "perfectMap_df.apply(buildPerfectMap,axis=1)\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "stopwords = stopwords.split('\\n')\n",
    "split_regex = r'\\w+'\n",
    "\n",
    "# TODO Implement this\n",
    "def simple_tokenize(string):\n",
    "    string=string.lower()\n",
    "    return re.findall(split_regex,string)\n",
    "def tokenize(string):\n",
    "    if not type(string) is str:return []\n",
    "    xx=simple_tokenize(string)\n",
    "    for i in stopwords:\n",
    "        while i in xx:\n",
    "            xx.remove(i)\n",
    "    return xx\n",
    "\n",
    "def rec2tok(x,dic):\n",
    "    #x:a record from on DataFrame\n",
    "    #dic:dictionary that build mappings from record id to tokens\n",
    "    if not type(x['description']) is str:x['description']=''\n",
    "    if not type(x['manufacturer']) is str:x['manufacturer']=''\n",
    "    dic[x['id']]=tokenize(x['title']+' '+x['description']+' '+x['manufacturer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def inc(i,dic):\n",
    "    #i:a key in dic\n",
    "    #dic:dic[i]++\n",
    "    if i in dic: dic[i]+=1\n",
    "    else: dic[i]=1\n",
    "    \n",
    "def tf(tokens):\n",
    "    tfs={}\n",
    "    for i in tokens: inc(i,tfs)            \n",
    "    n=float(len(tokens))\n",
    "    for i in tfs:tfs[i]/=n\n",
    "    return tfs\n",
    "def idf(rec2tok):\n",
    "    idfs={}\n",
    "    N=float(len(amazon_df)+len(google_df))\n",
    "    for i in rec2tok:\n",
    "        s=set(rec2tok[i])\n",
    "        for j in s:inc(j,idfs)\n",
    "    for i in idfs:idfs[i]=N/idfs[i]\n",
    "    return idfs\n",
    "def tfidf(tokens,idfs):\n",
    "    ans=tf(tokens)\n",
    "    s=set(tokens)\n",
    "    for i in ans:\n",
    "        ans[i]*=idfs[i]\n",
    "    return ans \n",
    "\n",
    "def invertIndex(forward_index):\n",
    "    #return a mapping from token to list-of-record-IDs\n",
    "    ans={}\n",
    "    for i in forward_index:\n",
    "        for j in forward_index[i]:\n",
    "            if j in ans:ans[j].append(i)\n",
    "            else: ans[j]=[i]\n",
    "    return ans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Optional utility\n",
    "def dotprod(a, b):\n",
    "    ans=0\n",
    "    for i in a:\n",
    "        if i in b: ans+=a[i]*b[i]\n",
    "    return ans\n",
    "\n",
    "# Optional utility\n",
    "def norm(a):\n",
    "    ans=0\n",
    "    for i in a:\n",
    "        ans+=a[i]**2\n",
    "    return math.sqrt(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "amazon_rec2tok = {}\n",
    "google_rec2tok = {}\n",
    "\n",
    "amazon_df.apply(lambda x:rec2tok(x,amazon_rec2tok),axis=1)\n",
    "google_df.apply(lambda x:rec2tok(x,google_rec2tok),axis=1)\n",
    "\n",
    "amazon_inv=invertIndex(amazon_rec2tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "idfs_full = dict(Counter(idf(amazon_rec2tok))+Counter(idf(google_rec2tok)))\n",
    "google_weights={i:tfidf(google_rec2tok[i],idfs_full) for i in google_rec2tok}\n",
    "amazon_weights={i:tfidf(amazon_rec2tok[i],idfs_full) for i in amazon_rec2tok}\n",
    "google_norm={i:norm(google_weights[i]) for i in google_weights}\n",
    "amazon_norm={i:norm(amazon_weights[i]) for i in amazon_weights}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def buildSim(Id,weight,norm,weights,norms,inv,sims):\n",
    "    #weights : Id->token->weight\n",
    "    #norms : Id->norm\n",
    "    for i in weight:\n",
    "        if i in inv:\n",
    "            for j in inv[i]:\n",
    "                if not (j,Id) in sims: sims[(j,Id)]=dotprod(weight,weights[j])/norm/norms[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "sims={}\n",
    "for i in google_weights:\n",
    "    buildSim(i,google_weights[i],google_norm[i],amazon_weights,amazon_norm,amazon_inv,sims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(...)? (4041431976.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[14], line 1\u001b[1;36m\u001b[0m\n\u001b[1;33m    print len(sims)# Should be 2441100\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(...)?\n"
     ]
    }
   ],
   "source": [
    "print (len(sims))# Should be 2441100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "true_dup_sims = []\n",
    "def truepos(threshold):\n",
    "    global true_dup_sims\n",
    "    true_dup_sims=[]\n",
    "    for i in sims:\n",
    "        if sims[i]>threshold: \n",
    "            true_dup_sims.append(i)\n",
    "def bin(similarity):\n",
    "    return int(similarity * nthresholds)\n",
    "\n",
    "# TODO Implement this\n",
    "def falsepos(threshold):\n",
    "    ans=0\n",
    "    for i in true_dup_sims:\n",
    "        if not i in perfectMap: ans+=1\n",
    "    return ans\n",
    "\n",
    "\n",
    "# TODO Implement this (returns a float)\n",
    "def precision(threshold):\n",
    "    truepos(threshold)\n",
    "    a=len(true_dup_sims)-falsepos(threshold)\n",
    "    b=len(true_dup_sims)\n",
    "    return a*1.0/b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "nthresholds=100\n",
    "thresholds = [float(n) / nthresholds for n in range(2, nthresholds)]\n",
    "p=[precision(n) for n in thresholds]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "plt.plot(thresholds,p)\n",
    "for i in range(0,98):\n",
    "    if p[i]==max(p): print \"最大准确率阈值\",thresholds[i]\n",
    "    \n",
    "print \"最大准确率：\",max(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
